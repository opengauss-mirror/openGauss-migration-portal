# configType.FiledType.FiledName="desc"
# config type (1:config.yml,2:application.yml,3:application-sink.yml,4:application-source.yml,5:mysql-sink.properties,6:mysql-source.properties,7:opengauss-sink.properties,8:opengauss-source.properties,9:migrationConfig.properties)
# FiledType (1:"string",2:"number",3:"boolean",4:"List",9:"object_arr");
1.1.sources.mysql.auto_maintenance=指定触发自动维护（vaccum）后的超时时间。参数接受对openGauss间隔数据类型(例如1 day)，如果设置为disabled自动维护不会运行。如果省略该参数，则默认值为disabled。
1.2.sources.pgsql.db_conn.connect_timeout=连接OpenGauss时的超时时间。较大的值可以帮助工具在慢速网络中更好地工作。低值可能会导致连接在执行任何操作之前失败。
1.3.sources.mysql.keep_existing_schema=当设置为Yes时，init_replica时不会使用MySQL源中的数据重新创建受影响的表。相反，现有表将被截断并重新加载数据。执行REINDEX表，以便在重新加载后使索引处于良好状态。这要求被复制的表已经在openGauss侧存在。当设置为No时，init_replica时会先删除openGauss测待复制的schema并重新创建。
1.2.sources.pgsql.db_conn.sleep_loop=两个副本批次之间的睡眠循环秒数。单位为秒。间隔N秒之后从MySQL读取下一批次数据。
1.4.sources.pgsql.db_conn.skip_tables=包含不被复制的表。同limit_tables一样，如果通过在线DDL更改了表名，skip_tables并不会一同更新。
1.1.rollbar_key=可选项。工具可配合rollbar(https://rollbar.com/)联合使用。如果在rollbar官网注册了账号，可将对应账号的POST_SERVER_ITEM_ACCESS_TOKEN填入rollbar_key。
1.4.sources.mysql.compress_tables=当启用行存表的压缩属性时，该参数用于指定用于压缩的表的白名单，支持表级和库级的表的白名单，默认对整个迁移的库按照参数compress_properties配置的 属性进行压缩，也可指定具体的表按照参数compress_properties配置的属性进行压缩。
1.1.sources.mysql.out_dir=如果copy_mode为file，则在init_replica过程中，表首先转储到csv文件中，然后在openGauss中重新加载。离线迁移过程中会在out_dir路径下自动创建子目录chameleon，csv文件存储于$out_dir/chameleon路径中，同时会在该路径存储离线迁移的表的元数据信息。
1.1.sources.mysql.copy_max_memory=在openGauss中复制表时要使用的最大内存量。可以指定以KB、MB、GB为单位的值，添加后缀（例如300M）。
1.4.sources.pgsql.db_conn.grant_select_to=在openGauss侧给指定的角色赋予对复制过来的表 select 权限。如果keep_existing_schema配置项设置为Yes，grant_select_to将不起作用。
1.1.sources.mysql.on_error_replay=指在 start_replica 阶段，openGauss侧重演失败时的动作。’exit’表示在openGauss侧重演失败时，退出复制进程。’continue’表示在openGauss侧重演失败时，从复制副本中删除失败的表，后续对于该表的改动不会再同步，同时继续其他表的复制。
1.2.log_days_keep=log文件保留时间，单位为天。
1.3.compress_properties.compress_byte_convert=行存表参数，设置行存表压缩字节转换预处理。在一些场景下可以提升压缩效果，同时会导致一定性能劣化。该参数允许修改，修改后决定变更数据、 新增数据是否进行字节转换预处理。当COMPRESS_DIFF_CONVERT为真时，该值不允许修改为假。取值范围：布尔值，默认关闭，设置为false。
1.1.log_level=log等级。有效值为 debug, info, warning, error, critical.
1.2.compress_properties.compress_chunk_size=行存表参数，设置行存表压缩chunk块大小。chunk数据块越小，预期能达到的压缩效果越好，同时数据越离散，影响表的访问速度。该参数生效后不允许修改。 （仅支持ASTORE下的普通表）。取值范围：与页面大小有关。在页面大小为8k场景，取值范围为：512、1024、2048、4096。 默认值：4096。
1.3.sources.mysql.enable_compress=用于指定是否启用行存表的压缩属性。默认为No，表示不启用。当设置为Yes时，表示启用压缩相关属性。压缩相关参数由compress_properties参数配置。 启用压缩属性的表由compress_tables参数配置。
1.1.sources.mysql.column_split=对于全量数据导入方式二，从指定CSV文件导入特定表的数据，该参数指定schema_table.csv文件多列之间的分隔符，默认值为','，可自定义。
1.1.sources.pgsql.db_conn.out_dir=如果copy_mode为file，则在init_replica过程中，表首先转储到csv文件中，然后在openGauss中重新加载。离线迁移过程中会在out_dir路径下自动创建子目录chameleon，csv文件存储于$out_dir/chameleon路径中，同时会在该路径存储离线迁移的表的元数据信息。
1.1.sources.pgsql.db_conn.type=指定源数据库类型。系统支持mysql或pgsql。其中pgsql是实验特性，暂时不建议使用。
1.1.sources.pgsql.db_conn.copy_max_memory=在openGauss中复制表时要使用的最大内存量。可以指定以KB、MB、GB为单位的值，添加后缀（例如300M）。
1.1.sources.mysql.db_conn.charset=database所指定的数据库的编码格式。
1.4.sources.mysql.skip_tables=包含不被复制的表。同limit_tables一样，如果通过在线DDL更改了表名，skip_tables并不会一同更新。
1.3.compress_properties.compress_diff_convert=行存表参数，设置行存表压缩字节差分预处理。只能与compress_byte_convert一起使用。在一些场景下可以提升压缩效果，同时会导致一定性能劣化。 该参数允许修改，修改后决定变更数据、新增数据是否进行字节差分预处理。取值范围：布尔值，默认关闭，设置为false。
1.4.sources.pgsql.db_conn.limit_tables=包含要复制的表。如果列表为空，则复制整个MySQL数据库。注意如果通过在线DDL更改了表名，limit_tables并不会一同更新。比如配置limit_tables为 my_sakila.test_table，然后在线复制阶段，在MySQL侧通过alter table test_table rename to test_table_rename; 那么后续对于test_table_rename的DML操作无法被同步。因为limit_tables记录的仍是rename之前的test_table，无法识别该表已经被rename成了test_table_rename。
1.4.sources.mysql.limit_tables=包含要复制的表。如果列表为空，则复制整个MySQL数据库。注意如果通过在线DDL更改了表名，limit_tables并不会一同更新。比如配置limit_tables为 my_sakila.test_table，然后在线复制阶段，在MySQL侧通过alter table test_table rename to test_table_rename; 那么后续对于test_table_rename的DML操作无法被同步。因为limit_tables记录的仍是rename之前的test_table，无法识别该表已经被rename成了test_table_rename。
1.1.pg_conn.charset=database所指定的数据库的编码格式。
1.2.sources.mysql.sleep_loop=两个副本批次之间的睡眠循环秒数。单位为秒。间隔N秒之后从MySQL读取下一批次数据。
1.2.compress_properties.compress_level=行存表参数，设置行存表压缩算法等级，仅当compresstype为2时生效。压缩等级越高，表的压缩效果越好，表的访问速度越慢。该参数允许修改， 修改后影响变更数据、新增数据的压缩等级。（仅支持ASTORE下的普通表）。取值范围：-31~31，默认值为0。
1.3.sources.mysql.contain_columns=对于全量数据导入方式二，从指定CSV文件导入特定表的数据，该参数指定schema_table.csv文件首行是否包含表的列名信息，默认值为No，表示不包含，此时将对表的所有列进行copy数据， csv文件对应列的顺序应和表的所有列的自然顺序保持一致。若取值为Yes，则表示文件首行为表的列名信息，copy数据时将跳过首行，对于多列信息，列名之间应按照','分隔，此时将对首行指定 的列进行copy数据。
1.1.sources.pgsql.db_conn.copy_mode=有效值为“file”和“direct”。“direct”会让复制实时进行。对于“file”，表首先转储到csv文件中，然后在openGauss中重新加载。csv文件存储的位置由out_dir配置。
1.1.sources.mysql.on_error_read=指在start_replica 阶段，连接MySQL失败时的动作。’exit’表示连接MySQL失败则退出进程。’continue’表示连接MySQL失败则一直重试。
1.1.sources.mysql.csv_dir=全量数据导入支持两种方式：(1)从MySQL库查询数据导入openGauss；(2)从指定CSV文件导入特定表的数据。该参数用于指定方式二从CSV文件直接进行全量数据导入的CSV文件目录。 其中一个表对应一个CSV文件，CSV文件命名规则为schema_table.csv。针对一个schema，若csv_dir为非法路径，或者该路径下未包含该schema对应表的CSV文件，该schema的表 数据将通过方式一从MySQL库查询数据导入openGauss；若该路径下包含部分表的CSV文件，将只迁移该部分表的结构及数据。
1.2.sources.mysql.index_parallel_workers=用于指定并发创建索引时bgworker的线程数，取值范围：[0, 32]，其中0表示关闭并发，默认值为2。当表数据量大于100000时，创建索引将通过该参数显式指定并发线程数。
1.2.compress_properties.compress_prealloc_chunks=行存表参数，设置行存表压缩chunk块预分配数量。预分配数量越大，表的压缩率相对越差，离散度越小，访问性能越好。该参数允许修改， 修改后影响变更数据、新增数据的预分配数量。（仅支持ASTORE下的普通表）。取值范围：0~7，默认值为0。 当COMPRESS_CHUNK_SIZE为512和1024时，支持预分配设置最大为7；当COMPRESS_CHUNK_SIZE为2048时，支持预分配设置最大为3； 当COMPRESS_CHUNK_SIZE为4096时，支持预分配设置最大为1。
1.2.sources.mysql.retry=对首次迁移失败的表，将加入迁移失败队列中，并增加重试机制，对失败的表重新进行迁移优先。该参数指定重试次数，取值为整数，默认值为3，可自定义。 若设置为正数，则表示进行有限次重试，当失败队列为空或者重试次数已达到上限，迁移进程将自行退出；若设置为0，则表示不重试；若设置为负数，将无限尝试直至所有表迁移成功，否则迁移进程不会退出。
1.3.sources.mysql.mysql_restart_config=用于指定是否允许重启Mysql数据库，其中修改参数重启数据库操作由用户完成。默认值为No。由于在线迁移需要开启binlog，并设置如下参数：log_bin=on，binlog_format=row，binlog_row_image=full，gtid_mode=on, 若Mysql初始配置与上述参数不一致，则需要修改参数并重启Mysql数据库，方可使用离线和在线功能。当该参数为No时，则表示不允许重启数据库，若在线迁移参数不符合要求，则不允许使用在线迁移功能，仅能在停止业务前提下使用离线迁移功能。
1.1.sources.mysql.copy_mode=有效值为“file”和“direct”。“direct”会让复制实时进行。对于“file”，表首先转储到csv文件中，然后在openGauss中重新加载。csv文件存储的位置由out_dir配置。
1.1.sources.pgsql.db_conn.charset=database所指定的数据库的编码格式
1.4.sources.mysql.grant_select_to=在openGauss侧给指定的角色赋予对复制过来的表 select 权限。如果keep_existing_schema配置项设置为Yes，grant_select_to将不起作用。
1.3.sources.mysql.gtid_enable=beta参数，默认设置为false。暂时不要启用。
1.3.dump_json=可选项。默认是No，当前开启时，在迁移过程中会在执行chameleon的地方生成json文件记录实时的迁移进度
1.1.rollbar_env=可选项。用于表示rollbar环境，与rollbar_key配合使用。若同时配置了 rollbar_key 和 rollbar_env，工具执行阶段的部分消息将被发送到 rollbar，可在rollbar官网登录自己的账号后看到相关消息。
1.1.sources.mysql.type=指定源数据库类型。系统支持mysql或pgsql。其中pgsql是实验特性，暂时不建议使用。
1.2.sources.mysql.writers=用于指定离线迁移过程中写线程的数目。
1.2.sources.mysql.db_conn.connect_timeout=连接MySQL时的超时时间。较大的值可以帮助工具在慢速网络中更好地工作。低值可能会导致连接在执行任何操作之前失败。
1.3.sources.mysql.migrate_default_value=是否迁移MySQL的默认值到openGauss。默认为Yes。由于列的默认值可以是表达式，部分MySQL的表达式若openGauss不支持的话，离线迁移过程中会报错，导致迁移失败。可通过将本值设置为No临时规避此类问题。
1.2.sources.mysql.readers=用于指定离线迁移过程中读线程的数目。
1.2.compress_properties.compresstype=行存表参数，设置行存表压缩算法。1代表pglz算法（不推荐使用），2代表zstd算法，默认不压缩。该参数生效后不允许修改。（仅支持ASTORE下的普通表）。 取值范围：0~2，默认值为0。
1.3.sources.mysql.is_create_index=用于指定全量迁移过程中，是否将表数据和索引分离。默认为Yes, 表示索引和表数据一起迁移。当设置为No时，表示只迁移表数据，并将索引任务写入文件中.
1.3.sources.mysql.is_skip_completed_tables=用于控制工具异常重启后是否跳过已经迁移完成的表
1.3.sources.mysql.index_dir=用于指定全量迁移过程中，当is_create_index设置为No时，存放索引任务的文件目录，索引文件为${index_dir}/tables.index。该文件中每一行对应一个表的索引。索引以json格式存储，key为表名，value为长度为5的列表，列表表示的信息依次为： 该表对应的索引信息、目标数据库schema、快照点、是否并行创建索引、自增列信息。
1.3.sources.mysql.with_datacheck=用于控制迁移工具是否与数据校验进行协同。
1.2.sources.mysql.slice_size=用于配置迁移工具与校验协同时，单个分片数据的行数，默认值为100000。该参数在with_datacheck为True/Yes时才生效。
2.2.spring.check.core-pool-size=并发线程数池设置，最小线程数
2.2.data.check.auto-delete-topic=配置是否自动删除Topic，0不删除，1校验全部完成后删除
2.2.data.check.max-retry-times=心跳等最大尝试次数
2.2.data.check.increment-max-diff-count=配置增量校验最大处理差异记录数，范围[10,5000]
2.2.spring.check.maximum-pool-size=并发线程数池设置，最大线程数
2.2.spring.check.maximum-topic-size=并发最大topic数量
3.3.spring.datasource.druid.test-while-idle=druid参数 test-while-idle
3.2.spring.datasource.druid.min-evictable-idle-time-millis=druid参数 min-evictable-idle-time-millis
3.3.spring.datasource.druid.keep-alive=druid参数 keep-alive
3.2.spring.check.core-pool-size=并发线程数池设置，最小线程数
3.2.spring.check.extend-maximum-pool-size=并发线程数池设置，最大线程数
3.2.spring.check.maximum-topic-size=并发最大topic数量
3.3.spring.datasource.druid.break-after-acquire-failure=druid参数 break-after-acquire-failure
3.3.spring.datasource.druid.test-on-borrow=druid参数 test-on-borrow
3.1.spring.datasource.driver-class-name=数据库驱动名称，可根据源端数据库类型配置
3.2.spring.datasource.druid.connection-error-retry-attempts=druid参数 connection-error-retry-attempts
3.2.spring.datasource.druid.max-wait=druid参数 max-wait
3.1.spring.extract.databaseType=暂无说明
3.2.spring.check.maximum-table-slice-size=并行抽取分片表记录数
3.2.spring.datasource.druid.validation-query-timeout=druid参数 validation-query-timeout
3.1.spring.extract.debezium-serializer=debezium 序列化方式 debezium
3.2.spring.check.maximum-pool-size=并发线程数池设置，最大线程数
3.1.spring.datasource.druid.validation-query=druid参数 validation-query
3.2.spring.datasource.druid.validation-query=当大表分片数超过20时，表级分片抽取并发线程池设置，最大线程数，可不修改，默认10
4.2.spring.datasource.druid.validation-query=当大表分片数超过20时，表级分片抽取并发线程池设置，最大线程数，可不修改，默认10
4.3.spring.datasource.druid.test-on-borrow=druid参数 test-on-borrow
4.2.spring.datasource.druid.min-evictable-idle-time-millis=druid参数 min-evictable-idle-time-millis
4.1.spring.datasource.driver-class-name=数据库驱动名称，可根据源端数据库类型配置
4.1.spring.extract.databaseType=暂无说明
4.2.spring.check.core-pool-size=并发线程数池设置，最小线程数
4.2.spring.check.extend-maximum-pool-size=并发线程数池设置，最大线程数
4.2.spring.datasource.druid.connection-error-retry-attempts=druid connection-error-retry-attempts 
4.3.spring.datasource.druid.keep-alive=druid参数keep-alive 
4.1.spring.extract.debezium-topic=debezium监听Topic名称，对应mysql-connect.properties配置文件 transforms.Reroute.topic.replacement 配置项
4.2.spring.check.maximum-table-slice-size=并行抽取分片表记录数
4.2.spring.check.maximum-pool-size=并发线程数池设置，最大线程数
4.3.spring.datasource.druid.test-while-idle=druid参数test-while-idle 
4.3.spring.datasource.druid.break-after-acquire-failure=druid参数 break-after-acquire-failure
4.1.spring.extract.dataLoadMode=暂无说明
4.1.spring.extract.debezium-serializer=暂无说明
4.2.spring.check.maximum-topic-size=并发最大topic数量
4.1.spring.extract.debezium-groupId=用于处理debezium监听的Topic数据 ，groupId消费Group设置
4.2.spring.datasource.druid.validation-query-timeout=druid参数  validation-query-timeout
4.2.spring.datasource.druid.max-wait=druid参数 max-wait 
4.1.spring.datasource.druid.validation-query=druid参数 validation-query
5.1.database.standby.hostnames=sink端数据库是主备部署时的备机ip列表，用逗号隔开，需与port列表一一对应，此配置项只对sink端是openGauss时起作用，默认值：""，不配置此项时sink端只连接主节点
5.1.database.standby.ports=sink端数据库是主备部署时的备机port列表，用逗号隔开，需与ip列表一一对应，此配置项只对sink端是openGauss时起作用，默认值：""，不配置此项时sink端只连接主节点
5.1.process.file.count.limit=进度目录下文件数目限制值，如果进度目录下的文件数目超过该值，工具启动时会按时间从早到晚删除多余的文件，默认值为10
5.1.topics=sink端从kafka抽取数据的topic，新增参数，String类型 与mysql-source.properties的配置项transforms.route.replacement相对应
5.1.append.write=进度文件写入方式，true表示追加写入，false表示覆盖写入，默认值为false
5.1.record.breakpoint.kafka.attempts=从kafka读取断点topic的最大重试次数
5.1.file.size.limit=文件大小限制，超过该限制值工具会另启新文件写入，默认为10，单位：兆
5.1.open.flow.control.threshold= 用于流量控制，新增参数，double类型，默认值为0.8，可自定义
5.1.record.breakpoint.kafka.clear.interval=断点记录Kafka的时间限制，超过该限制会触发删除Kafka的断点清除策略，删除无用的断点记录数据，单位：小时
5.1.parallel.replay.thread.num=并行回放默认线程数量，新增参数，int类型，默认为30，可自定义修改，取值需大于0
5.1.fail.sql.path=回放失败的sql语句输出路径，默认在迁移插件同一目录下
5.1.name=source端连接器名称，debezium的原生参数，无默认值，可自定义，不同连接器需保证名称的唯一性
5.1.process.file.time.limit=进度文件保存时长，超过该时长的文件会在工具下次启动时删除，默认值为168，单位：小时
5.1.create.count.info.path=记录源端日志生产起始点的文件读取路径，需与source端的此配置项相同，默认与迁移插件在同一目录下
5.1.record.breakpoint.kafka.size.limit=断点记录Kafka的条数限制，超过该限制会触发删除Kafka的断点清除策略，删除无用的断点记录数据，单位：事务万条数
5.1.commit.time.interval=迁移进度上报的时间间隔，取int型整数，默认为1，单位：s
5.1.xlog.location=增量迁移停止时openGauss端lsn的存储文件路径，新增参数，String类型，无默认值，根据实际自定义修改，需保证文件有读写权限
5.1.tasks.max=连接器创建的最大任务数，debezium的原生参数，默认值为1，MySQL connector通常为单任务
5.1.close.flow.control.threshold=用于流量控制，新增参数，double类型，默认值为0.7，可自定义
5.1.sink.process.file.path=迁移进度文件的输出路径，只有commit.process.while.running=true时才起作用，默认在迁移插件同一目录下
5.1.commit.process.while.running=布尔值，DataKit默认配置为true，通过该配置项选择是否上报迁移进度
5.1.queue.size.limit=存储kafka记录的队列的最大长度，新增参数，int类型，默认值为1000000，可自定义
5.1.record.breakpoint.repeat.count.limit=断点续传时，查询待回放数据是否已在断点之前备回放的数据条数，默认值：50000
5.1.wait.timeout.second=sink端数据库停止服务后迁移工具等待数据库恢复服务的最大时长，默认值：28800，单位：秒
6.1.tasks.max=连接器创建的最大任务数，debezium的原生参数，默认值为1，MySQL connector通常为单任务，不建议修改
6.1.parallel.parse.event=新增参数，boolean类型，是否启用并行解析event能力，默认为true，表示启用并行解析能力，若设置为false，则表示不启用并行解析能力，会降低在线迁移的性能
6.1.process.file.count.limit=进度目录下文件数目限制值，如果进度目录下的文件数目超过该值，工具启动时会按时间从早到晚删除多余的文件，默认值为10
6.1.snapshot.mode=快照模式，debezium的原生参数，默认值为initial，此处需设置为schema_only，不可修改
6.1.snapshot.offset.gtid.set=自定义配置快照点的Executed_Gtid_Set,跟全量迁移chameleon配合时，取决于全量迁移后从sch_chameleon.t_replica_batch表中列executed_gtid_set中查询的gtid set,需注意最大事务号需减1
6.1.name=source端连接器名称，debezium的原生参数，无默认值，可自定义，不同连接器需保证名称的唯一性
6.1.snapshot.offset.binlog.position=自定义配置快照点的binlog位置,跟全量迁移chameleon配合时，取决于全量迁移后从sch_chameleon.t_replica_batch表中列i_binlog_position中查询的binlog位置
6.1.bigint.unsigned.handing.mode=指定bigint unsigned数据类型的表示方式，debezium的原生参数，可选的值为long和precise。long对应Java的long类型，precise对应java.math.BigDecimal类型。对于大于等于2^63的值，会超出Java的long类型的存储范围，应该使用BigDecimal存储，即设置该值为precise
6.1.snapshot.offset.binlog.filename=自定义配置快照点的binlog文件名,跟全量迁移chameleon配合时，取决于全量迁移后从sch_chameleon.t_replica_batch表中列t_binlog_name中查询的binlog文件名
6.1.commit.process.while.running=布尔值，DataKit默认配置为true，通过该配置项选择是否上报迁移进度
6.1.commit.time.interval=迁移进度上报的时间间隔，取int型整数，默认为1，单位：s
6.1.append.write=进度文件写入方式，true表示追加写入，false表示覆盖写入，默认值为false
6.1.database.include.list=指定mysql库的白名单，debezium的原生参数，String类型，默认值为空字符串，表示捕获所有数据库的变更,若设置该值，则表示只捕获指定数据库的变更，多个库之间用逗号分隔
6.1.transforms.route.replacement=kafka topic路由转发后的topic名称，debezium提供topic路由能力，可自定义,该参数与mysql-sink.properties的配置项topics相对应
6.1.source.process.file.path=迁移进度文件的输出路径，只有commit.process.while.running=true时才起作用，默认在迁移插件同一目录下
6.1.create.count.info.path=记录源端日志生产起始点的文件输出路径，需与sink端的此配置项相同，默认与迁移插件在同一目录下
6.1.file.size.limit=文件大小限制，超过该限制值工具会另启新文件写入，默认为10，单位：兆
6.1.process.file.time.limit=进度文件保存时长，超过该时长的文件会在工具下次启动时删除，默认值为168，单位：小时
6.1.database.server.id= mysql数据库实例id，debezium的原生参数，取值为一个随机数，作为数据库的客户端id
6.1.open.flow.control.threshold= 当存储binlog事件的某一队列长度>最大长度queue.size.limit*该门限值时，将启用流量控制，暂停抽取binlog事件
6.1.close.flow.control.threshold= 当存储binlog事件的各个队列长度<最大长度queue.size.limit*该门限值时，将关闭流量控制，继续抽取binlog事件
6.1.queue.size.limit= source端抽取binlog事件存储队列的最大长度，int类型，默认值为1000000，可自定义
6.1.max.start.memory= 自定义debezium最大启动内存
6.1.min.start.memory= 自定义debezium最小启动内存
6.1.bigint.unsigned.handling.mode= 对于大于等于2^63的值，会超出Java的long类型的存储范围，应该使用BigDecimal存储，即设置该值为precise
6.1.provide.transaction.metadata=指定连接器是否存储事务元数据信息，debezium的原生参数，boolean类型，配置为true时并行回放模式为按事务并行回放，配置为false时并行回放模式为按表并行回放，默认为false
6.1.wait.timeout.second=自定义JDBC连接在被服务器自动关闭之前等待活动的秒数。如果客户端在这段时间内没有向服务器发送任何请求，服务器将关闭该连接，默认值：28800，单位：秒
7.1.sink.process.file.path=迁移进度文件的输出路径，只有commit.process.while.running=true时才起作用，默认在迁移插件同一目录下
7.1.record.breakpoint.kafka.size.limit=断点记录Kafka的条数限制，超过该限制会触发删除Kafka的断点清除策略，删除无用的断点记录数据，单位：事务万条数
7.1.file.size.limit=文件大小限制，超过该限制值工具会另启新文件写入，默认为10，单位：兆
7.1.open.flow.control.threshold=用于流量控制，新增参数，double类型，默认值为0.8，可自定义
7.1.process.file.count.limit=进度目录下文件数目限制值，如果进度目录下的文件数目超过该值，工具启动时会按时间从早到晚删除多余的文件，默认值为10
7.1.name=sink端连接器名称
7.1.delete.full.csv.file=控制在全量数据迁移处理完csv文件后是否删除文件，默认值false.
7.1.close.flow.control.threshold=用于流量控制，新增参数，double类型，默认值为0.7，可自定义
7.1.process.file.time.limit=进度文件保存时长，超过该时长的文件会在工具下次启动时删除，默认值为168，单位：小时
7.1.commit.process.while.running=布尔值，默认为false，通过该配置项选择是否上报迁移进度
7.1.append.write=进度文件写入方式，true表示追加写入，false表示覆盖写入，默认值为false
7.1.fail.sql.path=回放失败的sql语句输出路径，默认在迁移插件同一目录下
7.1.topics=sink端从kafka抽取数据的topic，与opengauss-source.properties配置项transforms.route.replacement对应
7.1.record.breakpoint.kafka.attempts=从kafka读取断点topic的最大重试次数
7.1.create.count.info.path=记录源端有效日志生产总数的文件读取路径，需与source端的此配置项相同，默认与迁移插件在同一目录下
7.1.record.breakpoint.kafka.clear.interval=断点记录Kafka的时间限制，超过该限制会触发删除Kafka的断点清除策略，删除无用的断点记录数据，单位：小时
7.1.commit.time.interval=迁移进度上报的时间间隔，取int型整数，默认为1，单位：s
7.1.max.thread.count=最大并发线程数
7.1.database.type=数据库类型,当前支持mysql opengauss 和oracle,默认值是mysql
7.1.queue.size.limit=存储kafka记录的队列的最大长度，新增参数，int类型，默认值为1000000，可自定义
7.1.record.breakpoint.repeat.count.limit=断点续传时，查询待回放数据是否已在断点之前备回放的数据条数，默认值：50000
7.1.wait.timeout.second=sink端数据库停止服务后迁移工具等待数据库恢复服务的最大时长，默认值：28800，单位：秒
8.1.database.iscluster=opengauss数据库是否为集群，可选择true/false，默认值为false，选择true时，需配置database.standby.hostnames和database.standby.ports
8.1.database.standby.hostnames=opengauss数据库备机ip1,ip2,...，多个备机ip间用英文逗号隔开
8.1.database.standby.ports=opengauss数据库备机端口port1,port2,...，多个备机port间用英文逗号隔开，注意需要与备机ip1,ip2,...保持对应
8.1.create.count.info.path=记录源端有效日志生产总数的文件输出路径，需与sink端的此配置项相同，默认与迁移插件在同一目录下
8.1.process.file.time.limit=进度文件保存时长，超过该时长的文件会在工具下次启动时删除，默认值为168，单位：小时
8.1.append.write=进度文件写入方式，true表示追加写入，false表示覆盖写入，默认值为false
8.1.process.file.count.limit=进度目录下文件数目限制值，如果进度目录下的文件数目超过该值，工具启动时会按时间从早到晚删除多余的文件，默认值为10
8.1.name=source端连接器名称
8.1.commit.process.while.running=布尔值，默认为false，通过该配置项选择是否上报迁移进度
8.1.commit.time.interval=迁移进度上报的时间间隔，取int型整数，默认为1，单位：s
8.1.file.size.limit=文件大小限制，超过该限制值工具会另启新文件写入，默认为10，单位：兆
8.1.source.process.file.path=迁移进度文件的输出路径，只有commit.process.while.running=true时才起作用，默认在迁移插件同一目录下
8.1.transforms= kafka topic路由转发名称
8.1.transforms.route.regex=kafka topic路由转发正则匹配表达式，正则匹配按照前缀匹配
8.1.snapshot.mode=快照模式，默认为never
8.1.transforms.route.replacement=kafka topic路由转发后的topic名称，该参数与opengauss-sink.properties的配置项topics相对应
8.1.export.csv.path=全量数据文件大小划分配置，支持K、M、G大小配置，没有单位默认按照M单位处理，默认值为 2M
8.1.tasks.max=连接器创建的最大任务数
8.1.export.csv.path.size=文件夹大小控制 支持K、M、G大小配置，没有单位时默认按照G单位处理，默认值为null
8.1.slot.drop.on.stop=停止时删除逻辑复制槽与发布订阅，默认为true
8.1.slot.name=opengauss逻辑复制槽名称
8.1.export.file.size=全量数据文件大小划分配置，支持K、M、G大小配置，没有单位默认按照M单位处理，默认值为 2M
8.1.max.start.memory=自定义debezium最大启动内存
8.1.min.start.memory=自定义debezium最小启动内存
8.1.reconnection.number=迁移过程中数据库异常时，尝试重连的次数，默认值12，需要与reconnection.time.interval配合使用
8.1.reconnection.time.interval=迁移过程中数据库异常时，每次尝试重连的时间间隔，单位毫秒（ms），默认值5000，需要与reconnection.number配合使用
8.1.wal.sender.timeout=设置建立openGauss会话时的guc参数wal_sender_timeout的值，单位毫秒（ms），默认值6000。wal_sender_timeout参数说明：设置本端等待事务日志接收端接收日志的最大等待时间。
8.1.plugin.name=反向迁移时，创建逻辑复制槽的插件名称，默认为pgoutput，可设置为mppdb_decoding实现并行解码
9.1.mysql.database.table=配置迁移表的白名单，格式为schemaName.tableName，这里显示的是初始默认值，真实值为选源端库表时选定的表，保存迁移任务的时候选定的表会覆盖该默认值，这里不显示真实值
9.1.opengauss.database.iscluster=opengauss数据库是否为集群，可选择true/false，选择true时，需配置opengauss.database.standby.hostnames和opengauss.database.standby.ports
9.1.opengauss.database.standby.hostnames=opengauss数据库备机ip1,ip2,...，多个备机ip间用英文逗号隔开
9.1.opengauss.database.standby.ports=opengauss数据库备机端口port1,port2,...，多个备机port间用英文逗号隔开，注意需要与备机ip1,ip2,...保持对应
9.1.full.check.extract.source.jvm=全量数据校验source进程jvm参数设置
9.1.full.check.extract.sink.jvm=全量数据校验sink进程jvm参数设置
9.1.full.check.jvm=全量数据校验check进程jvm参数设置
9.1.incremental.check.extract.sink.jvm=增量数据校验sink进程jvm参数设置
9.1.incremental.check.extract.source.jvm=增量数据校验source进程jvm参数设置
9.1.incremental.check.jvm=增量数据校验check进程jvm参数设置
9.1.incremental.source.numa.params=增量迁移source端性能参数设置
9.1.incremental.sink.numa.params=增量迁移sink端性能参数设置
9.1.reverse.source.numa.params=反向迁移source端性能参数设置
9.1.reverse.sink.numa.params=反向迁移sink端性能参数设置
9.1.global.log.level=工具全局日志参数设置 有效值为 debug, info, warning, error, critical.
